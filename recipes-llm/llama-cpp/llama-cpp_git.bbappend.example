# Example bbappend for customizing llama-cpp build
# Place this file as: meta-ollama-cpp/recipes-llm/llama-cpp/llama-cpp_git.bbappend

# Enable additional features for specific machines
# This demonstrates how users can customize the build

# Example: Enable BLAS for better performance (requires openblas)
# EXTRA_OECMAKE:append = " -DLLAMA_BLAS=ON"
# DEPENDS:append = " openblas"

# Example: Increase optimization level
# EXTRA_OECMAKE:append = " -DCMAKE_BUILD_TYPE=Release"

# Example: Build additional tools
# EXTRA_OECMAKE:append = " -DLLAMA_BUILD_TESTS=ON"

# Example: Custom installation path for tools
# do_install:append() {
#     # Install additional utilities
#     if [ -f ${B}/bin/embedding ]; then
#         install -m 0755 ${B}/bin/embedding ${D}${bindir}/llama-embedding
#     fi
# }

# Example: Architecture-specific optimizations
# For Raspberry Pi 4
# EXTRA_OECMAKE:append:raspberrypi4-64 = " -DLLAMA_NATIVE=ON"

# For specific x86-64 processors
# EXTRA_OECMAKE:append:intel-corei7-64 = " -DLLAMA_AVX512=ON"
